<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Â∞πÁ•∫Áøî">





<title>ÊñáÊú¨ÂàÜÁ±ª‰ªªÂä°Ê¶ÇËø∞ | yqxBlog</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
            <!-- MathJaxÈÖçÁΩÆÔºåÂèØÈÄöËøáÂçïÁæéÂÖÉÁ¨¶Âè∑‰π¶ÂÜôË°åÂÜÖÂÖ¨ÂºèÁ≠â -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- ÁªôMathJaxÂÖÉÁ¥†Ê∑ªÂä†has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- ÈÄöËøáËøûÊé•CDNÂä†ËΩΩMathJaxÁöÑjs‰ª£Á†Å -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<meta name="generator" content="Hexo 5.4.2">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "¬∑ Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "¬∑ Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">BUPTyqx&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">BUPTyqx&#39;s Blog</a><a id="mobile-toggle-theme">¬∑&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6; // ‰∏∫ 6 Êó∂Â±ïÂºÄÊâÄÊúâ
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function() {
            tocbot.refresh(obj_merge(tocbot_default_config, {
                hasInnerContainers: true
            }));
        }, 420); // Ëøô‰∏™ÂÄºÊòØÁî± tocbot Ê∫êÁ†ÅÈáåÂÆö‰πâÁöÑ scrollSmoothDuration ÂæóÊù•ÁöÑ
    }

    document.ready(function() {
        tocbot.init(obj_merge(tocbot_default_config, {
            collapseDepth: 1
        }));
    });

    function expand_toc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, {
            collapseDepth: expanded ? 1 : DEPTH_MAX
        }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">ÊñáÊú¨ÂàÜÁ±ª‰ªªÂä°Ê¶ÇËø∞</h1>
            
                <div class="post-meta">
                    
                        ü¶π‚Äç‚ôÄÔ∏è‰ΩúËÄÖ: <a itemprop="author" rel="author" href="/">Â∞πÁ•∫Áøî</a><br>
                    

                    
                        <span class="post-time">
                        ‚è≤Ô∏èÊó∂Èó¥: <a href="#">August 16, 2022&nbsp;&nbsp;15:02:04</a><br>
                        </span>
                    
                    
                        <span class="post-category">
                            üìíÁõÆÂΩï:
                            
                                <a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ</a><br>
                            
                        </span>
                    
                    
                    
                        <span class="post-count">
                            üìëÂ≠óÊï∞:
                        <a href="">1,594</a><br>  
                        </span>
                    
                    
                        <span class="post-count">
                    ‚è∞È¢ÑËÆ°ÈòÖËØªÊó∂Èó¥:
                        <a href="">9min</a>  
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="Text-Classification"><a href="#Text-Classification" class="headerlink" title="Text Classification"></a>Text Classification</h1><h2 id="1-Ê¶ÇËø∞"><a href="#1-Ê¶ÇËø∞" class="headerlink" title="1. Ê¶ÇËø∞"></a>1. Ê¶ÇËø∞</h2><ul>
<li>Text Classification is a technique of <strong>categorizing</strong> natural language texts into <strong>pre-defined</strong>, organized <strong>groups</strong></li>
<li>In other words - it is the activity of labeling texts with categories from a pre-defined set, based upon the content</li>
<li><p>Classic examples include classification of books in libraries or segmentation of articles in news,by looking at the content.</p>
</li>
<li><p>Text classification is a sub-field of <strong>text analytics</strong>, which uses <strong>machine learning</strong> to extract meaning from text documents</p>
</li>
<li>Text classification technique has been used successfully for:<ul>
<li>Sentiment analysis</li>
<li>Topic detection</li>
<li>Language detection</li>
<li>Fraud, Profanity, and Emergency detection</li>
<li>Urgency detection in customer support</li>
</ul>
</li>
</ul>
<h2 id="2-Machine-Learning"><a href="#2-Machine-Learning" class="headerlink" title="2. Machine Learning"></a>2. Machine Learning</h2><blockquote>
<p>ÂèÇËÄÉÈìæÊé•Ôºö</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.lexalytics.com/technology/text-analytics/">https://www.lexalytics.com/technology/text-analytics/</a></li>
</ul>
</blockquote>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816152416947.png" alt="image-20220816152416947"></p>
<p><strong>machine learning for NLP</strong></p>
<ul>
<li>Processing natural language text is complex, and the traditional rules-based, explicit programming is not practical</li>
<li>Machine Learning allows <strong>algorithms</strong> to <strong>iteratively learn</strong> from text and extract rules, instead of explicitly programming for it</li>
<li>Machine learning can improve, accelerate and automate NLP tasks and text analytics functions</li>
</ul>
<p>Core NLP tasks are performed with machine learning models:</p>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/1-1024x773.png" alt="img"></p>
<p>Machine Learning Process:CRISP-DM</p>
<ul>
<li>The Cross-Industry-StandardProcess-for-Data-Mining (<strong>CRISP-DM</strong>), a well-established scientific method</li>
<li>Process Steps are:<ul>
<li>Business Understanding</li>
<li>Data Understanding</li>
<li>Data Preparation</li>
<li>Modeling</li>
<li>Evaluation</li>
<li>Deployment</li>
</ul>
</li>
</ul>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/CRISP-DM.png" alt="CRISP DM"></p>
<p><strong>Model Building &amp; Evaluation Deep Dive</strong></p>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816154743234.png" alt="image-20220816154743234"></p>
<h2 id="3-Classification-Modeling-Example"><a href="#3-Classification-Modeling-Example" class="headerlink" title="3. Classification Modeling Example"></a>3. Classification Modeling Example</h2><p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816155427886.png" alt="image-20220816155427886"></p>
<p><strong>model evaluation-Confusion Matrix</strong></p>
<p>For the classification problem,you predict either right or wrong-however,there are two dimensions to evaluate the result.</p>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816160721419.png" alt="image-20220816160721419"></p>
<p>#Correct Predictions/Total # Predictions Ability to find all relevant cases within</p>
<p>dataset. Tells us how complete the result is Ability to find only the relevant data points. Tells us how valid the result is</p>
<p>Harmonic mean of recall and precision </p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Metric</th>
<th>Definition</th>
<th>Calculations using confusion matrix</th>
</tr>
</thead>
<tbody>
<tr>
<td>Accuracy</td>
<td>#Correct Predictions/Total # Predictions</td>
<td>$(TP+TN)/Total$</td>
</tr>
<tr>
<td>Recall(sensitivity)</td>
<td>Ability to find all relevant cases within dataset. Tells us how complete the result is</td>
<td>$(TP)/(TP+FN)$</td>
</tr>
<tr>
<td>Precision</td>
<td>Ability to find only the relevant data points. Tells us how valid the result is</td>
<td>$(TP)/(TP+FP)$</td>
</tr>
<tr>
<td>F1-Score</td>
<td>Harmonic mean of recall and precision</td>
<td>$F1=2\times \frac{\text{precision}\times\text{recall}}{\text{precision}+\text{recall}}$</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>An example:</p>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816162226429.png" alt="image-20220816162226429"></p>
</blockquote>
<h2 id="4-scikit-learn"><a href="#4-scikit-learn" class="headerlink" title="4. scikit-learn"></a>4. scikit-learn</h2><p>ÂÆâË£ÖÔºö</p>
<figure class="highlight cmd"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scikit-learn</span><br></pre></td></tr></tbody></table></figure>
<p>Scikit usage steps(5 high level steps)</p>
<ol>
<li><p>select a model(estimator object)</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">model = LinearRegression(normalize = <span class="literal">True</span>)</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>Split the data into test and training sets</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.3</span>)</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>Train/fit the model</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(X_train, t_train)</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>Predict Labels for test data</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predictions = model.predict(X_test)</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>Evaluate model(create metrics)</p>
</li>
</ol>
<p><strong>sklearn demo</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">'./smsspamcollection.tsv'</span>, sep=<span class="string">'\t'</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816182518300.png" alt="image-20220816182518300"></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Êü•ÁúãÊòØÂê¶ÊúâÁº∫Â§±ÁöÑÊï∞ÊçÆ</span></span><br><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816182535097.png" alt="image-20220816182535097"></p>
<p>ÂèØ‰ª•ÁúãÂà∞Ê≠§Êó∂Êï∞ÊçÆÈõÜ‰∏≠Ê≤°ÊúâÁ©∫Áº∫È°πÔºåÂ¶ÇÊûúÊúâÁ©∫Áº∫È°πÔºåÂèØ‰ª•‰ΩøÁî®‰∏ãÈù¢ÁöÑ‰ª£Á†ÅË°•ÂÖÖÁ©∫Áº∫Ôºö</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">blanks = []  <span class="comment"># start with an empty list</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index,label,review <span class="keyword">in</span> df.itertuples():   <span class="comment"># iterate over the DataFrame</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(review)==<span class="built_in">str</span>:                    <span class="comment"># avoid NaN values</span></span><br><span class="line">        <span class="keyword">if</span> review.isspace():                 <span class="comment"># test 'review' for whitespace</span></span><br><span class="line">            blanks.append(index)             <span class="comment"># add matching index to list</span></span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(blanks), <span class="string">'blanks: '</span>, blanks)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220817160730279.png" alt="image-20220817160730279"></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(df[<span class="string">'label'</span>].unique())       <span class="comment"># Êü•ÁúãÁ±ªÂà´</span></span><br><span class="line"><span class="built_in">print</span>(df[<span class="string">'label'</span>].value_counts()) <span class="comment"># Êü•ÁúãÊØè‰∏™Á±ªÂà´ÂØπÂ∫îÁöÑÊï∞ÊçÆÊï∞Èáè</span></span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816182554421.png" alt="image-20220816182554421"></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ÂØπÊüê‰∏ÄÊï∞ÊçÆËøõË°åÁªüËÆ°ÊèèËø∞</span></span><br><span class="line">df[<span class="string">'length'</span>].describe()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816182620447.png" alt="image-20220816182620447"></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = df[[<span class="string">'length'</span>,<span class="string">'punct'</span>]]</span><br><span class="line">y = df[<span class="string">'label'</span>]</span><br><span class="line"><span class="built_in">print</span>(X.shape)</span><br><span class="line"><span class="built_in">print</span>(y.shape)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816182659450.png" alt="image-20220816182659450"></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># ÂàíÂàÜÊï∞ÊçÆÈõÜÂíåÈ™åËØÅÈõÜ</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, </span><br><span class="line">                                                    test_size=<span class="number">0.33</span>, </span><br><span class="line">                                                    random_state=<span class="number">42</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Training Data Shape:'</span>, X_train.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Testing Data Shape: '</span>, X_test.shape)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816182719587.png" alt="image-20220816182719587"></p>
<p><strong>ÂàõÂª∫‰∏Ä‰∏™LogisticRegressionÊ®°Âûã</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Âª∫Á´ãÊ®°Âûã</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr_model = LogisticRegression(solver=<span class="string">'lbfgs'</span>)</span><br><span class="line">lr_model.fit(X_train, y_train)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816182740106.png" alt="image-20220816182740106"></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="comment"># ÂàõÂª∫‰∏Ä‰∏™È¢ÑÊµã</span></span><br><span class="line">predictions = lr_model.predict(X_test)</span><br><span class="line"><span class="comment"># ËæìÂá∫Ê∑∑Ê∑ÜÁü©Èòµ</span></span><br><span class="line"><span class="built_in">print</span>(metrics.confusion_matrix(y_test,predictions))</span><br><span class="line"><span class="comment"># ËæìÂá∫ÂàÜÁ±ªÊä•Âëä</span></span><br><span class="line"><span class="built_in">print</span>(metrics.classification_report(y_test,predictions))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816182819923.png" alt="image-20220816182819923"></p>
<p> <strong>ÂàõÂª∫‰∏Ä‰∏™Êú¥Á¥†Ë¥ùÂè∂ÊñØÊ®°Âûãna√Øve Bayes classifier</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train a na√Øve Bayes classifier:</span></span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line">nb_model = MultinomialNB()</span><br><span class="line">nb_model.fit(X_train, y_train)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">predictions = nb_model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(metrics.confusion_matrix(y_test,predictions))</span><br><span class="line"><span class="built_in">print</span>(metrics.classification_report(y_test,predictions))</span><br><span class="line"><span class="built_in">print</span>(metrics.accuracy_score(y_test,predictions))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816182908561.png" alt="image-20220816182908561"></p>
<p> <strong>ÂàõÂª∫‰∏Ä‰∏™ÊîØÊåÅÂêëÈáèÊú∫Ê®°Âûãsvc</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">svc_model = SVC(gamma=<span class="string">'auto'</span>)</span><br><span class="line">svc_model.fit(X_train,y_train)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">predictions = svc_model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(metrics.confusion_matrix(y_test,predictions))</span><br><span class="line"><span class="built_in">print</span>(metrics.classification_report(y_test,predictions))</span><br><span class="line"><span class="built_in">print</span>(metrics.accuracy_score(y_test,predictions))</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816183001913.png" alt="image-20220816183001913"></p>
<h2 id="5-Text-Feature-Extraction"><a href="#5-Text-Feature-Extraction" class="headerlink" title="5. Text Feature Extraction"></a>5. Text Feature Extraction</h2><ul>
<li>Machine learning algorithms (models) need numerical features to perform learning and prediction activities</li>
<li>We need to <strong>extract</strong> numerical features from the raw text </li>
</ul>
<h3 id="5-1-count-vectorization"><a href="#5-1-count-vectorization" class="headerlink" title="5.1 count vectorization"></a>5.1 count vectorization</h3><p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816183842413.png" alt="image-20220816183842413"></p>
<p><code>CountVectorizer</code> Á±ªÔºö</p>
<ul>
<li>create a matrix of counts,with columns as wordsÔºå‰ºöÂ∞ÜÊñáÊú¨‰∏≠ÁöÑËØçËØ≠ËΩ¨Êç¢‰∏∫ËØçÈ¢ëÁü©Èòµ</li>
<li>Áü©Èòµ‰∏≠ÂåÖÂê´‰∏Ä‰∏™ÂÖÉÁ¥†<code>a[i][j]</code>ÔºåÂÆÉË°®Á§∫<code>j</code>ËØçÂú®<code>i</code>Á±ªÊñáÊú¨‰∏ãÁöÑËØçÈ¢ë„ÄÇThis sparse matrix is called Document Term Matrix(DTM)</li>
<li><code>fit_transform</code>ÂáΩÊï∞ËÆ°ÁÆóÂêÑ‰∏™ËØçËØ≠Âá∫Áé∞ÁöÑÊ¨°Êï∞</li>
<li><code>get_feature_names()</code>ÂèØËé∑ÂèñËØçË¢ã‰∏≠ÊâÄÊúâÊñáÊú¨ÁöÑÂÖ≥ÈîÆÂ≠óÔºå</li>
<li><code>toarray()</code>ÂèØÁúãÂà∞ËØçÈ¢ëÁü©ÈòµÁöÑÁªìÊûú„ÄÇ</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Scikit-learn's CountVectorizer</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line">count_vect = CountVectorizer()</span><br><span class="line">X_train_counts = count_vect.fit_transform(X_train)</span><br><span class="line">X_train_counts.shape</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816185514946.png" alt="image-20220816185514946"></p>
<h3 id="5-2-Term-Frequency-TF"><a href="#5-2-Term-Frequency-TF" class="headerlink" title="5.2 Term Frequency(TF)"></a>5.2 Term Frequency(TF)</h3><ul>
<li>Term Frequency <code>tf(t,d)</code>-raw count of a term in a document, i.e.,the number of times a term <code>t</code> occurs in document <code>d</code></li>
<li>However,Term Frequency alone is not enough for a thorough feature analysis of the text. Consider stop words like ‚Äúa‚Äù or ‚Äúthe‚Äù </li>
<li>Because the term ‚Äúthe‚Äù is so common, term frequency will tend to incorrectly emphasize documents which happen to use the word ‚Äúthe‚Äù more frequently, without giving enough weight to the more meaningful terms ‚Äúred‚Äù and ‚Äúdogs‚Äù.</li>
</ul>
<h3 id="5-3-Inverse-Document-Frequency-IDF"><a href="#5-3-Inverse-Document-Frequency-IDF" class="headerlink" title="5.3 Inverse Document Frequency(IDF)"></a>5.3 Inverse Document Frequency(IDF)</h3><ul>
<li>In order to reduce the unwanted impact of common words, an <strong>inverse document frequency</strong> factor is incorporated which diminishes the weight of terms that occur very frequently in the document set and increases the weight of terms that occur rarely</li>
<li>It is the logarithmically scaled inverse fraction of the documents that contain the word (obtained by dividing the total number of documents by the number of documents containing the term, and then taking the logarithm of that quotient)</li>
</ul>
<h3 id="5-4-TF-IDF"><a href="#5-4-TF-IDF" class="headerlink" title="5.4 TF-IDF"></a>5.4 TF-IDF</h3><ul>
<li>TF-IDF = Term Frequency * (1/document Frequency)</li>
<li>TF-IDF = Term Frequency * Inverse Document Frequency</li>
</ul>
<script type="math/tex; mode=display">
\begin{align}

\operatorname{tfidf}(t, d, D) & = \operatorname{tf}(t, d) \cdot \operatorname{idf}(t, D) \\
\operatorname{idf}(t, D) & = \log \frac{N}{|\{d \in D: t \in d\}|}

\end{align}</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Transform Counts to Frequencies with Tf-idf</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfTransformer</span><br><span class="line">tfidf_transformer = TfidfTransformer()</span><br><span class="line">X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)</span><br><span class="line">X_train_tfidf.shape</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816185638730.png" alt="image-20220816185638730"></p>
<h3 id="5-5-TF-IDF-Vectorizer"><a href="#5-5-TF-IDF-Vectorizer" class="headerlink" title="5.5 TF-IDF Vectorizer"></a>5.5 TF-IDF Vectorizer</h3><ul>
<li>TF-IDF Vectorizer is superior to raw Count Vectorizer</li>
<li>TF-IDF allows us to understand the context of words across an <strong>entire corpus of documents</strong>, instead of just its relative importance in a single document</li>
<li>Scikit-Learn‚Äôs <code>TfidfVectorizer</code> to train and fit our models </li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line">vectorizer = TfidfVectorizer()</span><br><span class="line">X_train_tfidf = vectorizer.fit_transform(X_train) </span><br><span class="line"><span class="comment"># ‰ΩøÁî®ÂéüÂßãÁöÑX_train</span></span><br><span class="line">X_train_tfidf.shape</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220816185819948.png" alt="image-20220816185819948"></p>
<h3 id="5-6-Pipline"><a href="#5-6-Pipline" class="headerlink" title="5.6 Pipline"></a>5.6 Pipline</h3><ul>
<li>Pipeline of transforms with a final estimator.</li>
<li>Sequentially apply a list of transforms and a final estimator. Intermediate steps of the pipeline must be ‚Äòtransforms‚Äô, that is, they must implement <code>fit</code> and <code>transform</code> methods. The final estimator only needs to implement <code>fit</code>. The transformers in the pipeline can be cached using <code>memory</code> argument.</li>
<li>The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. For this, it enables setting parameters of the various steps using their names and the parameter name separated by a <code>'__'</code>, as in the example below. A step‚Äôs estimator may be replaced entirely by setting the parameter with its name to another estimator, or a transformer removed by setting it to <code>'passthrough'</code> or <code>None</code>.</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line">text_clf = Pipeline([(<span class="string">'tfidf'</span>, TfidfVectorizer()), (<span class="string">'clf'</span>, LinearSVC())])</span><br><span class="line"><span class="comment"># Feed the training data through the pipeline</span></span><br><span class="line">text_clf.fit(X_train, y_train)  </span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220817145239824.png" alt="image-20220817145239824"></p>
<p>ÂØπÈ¢ÑÊµãÁªìÊûúËøõË°åËØÑ‰º∞È™åËØÅÔºåÂèØ‰ª•ÂèëÁé∞Ê≠§Êó∂ÂáÜÁ°ÆÂ∫¶ÊúâÊòéÊòæÁöÑÊèêÂçáÔºö</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">predictions = text_clf.predict(X_test)    <span class="comment"># È¢ÑÊµã</span></span><br><span class="line"><span class="built_in">print</span>(metrics.confusion_matrix(y_test,predictions))      <span class="comment"># Ê∑∑Ê∑ÜÁü©Èòµ</span></span><br><span class="line"><span class="built_in">print</span>(metrics.classification_report(y_test,predictions)) <span class="comment"># È¢ÑÊµãÊä•Âëä</span></span><br><span class="line"><span class="built_in">print</span>(metrics.accuracy_score(y_test,predictions))        <span class="comment"># È¢ÑÊµãÂáÜÁ°ÆÂ∫¶</span></span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220817150011864.png" alt="image-20220817150011864"></p>
<p>‰ΩøÁî®ËØ•ÁÆóÊ≥ïÈ¢ÑÊµã‰∏§‰∏™Âè•Â≠êÔºö</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">text_clf.predict([<span class="string">"Hello, how are you?"</span>])</span><br><span class="line">text_clf.predict([<span class="string">'Congratulations, you have won $1 M'</span>])</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/08/16/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E6%A6%82%E8%BF%B0/image-20220817151218786.png" alt="image-20220817151218786"></p>
<p>Text Classification Project:</p>
<ul>
<li>Read in a collection of documents - a <strong>corpus</strong></li>
<li>Transform text into numerical vector data using a pipeline</li>
<li>Create a classifier</li>
<li>Fit/train the classifier</li>
<li>Test the classifier on new data</li>
<li>Evaluate performance</li>
</ul>

        </div>

        
            <section class="post-copyright">
                
                
                
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E7%BC%96%E7%A8%8B/">üè∑Ô∏èÁºñÁ®ã</a>
                    
                        <a href="/tags/python/">üè∑Ô∏èpython</a>
                    
                        <a href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">üè∑Ô∏èËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>¬∑ </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
            
            <a class="next" rel="next" href="/2022/07/23/python%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/">NLPÂü∫Á°ÄÂ∑•ÂÖ∑</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>¬© Â∞πÁ•∫Áøî | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>

</html>