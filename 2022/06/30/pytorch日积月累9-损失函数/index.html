<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="å°¹ç¥ºç¿”">





<title>pytorchæ—¥ç§¯æœˆç´¯-æŸå¤±å‡½æ•° | yqxBlog</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
            <!-- MathJaxé…ç½®ï¼Œå¯é€šè¿‡å•ç¾å…ƒç¬¦å·ä¹¦å†™è¡Œå†…å…¬å¼ç­‰ -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- ç»™MathJaxå…ƒç´ æ·»åŠ has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- é€šè¿‡è¿æ¥CDNåŠ è½½MathJaxçš„jsä»£ç  -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<meta name="generator" content="Hexo 5.4.2">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "Â· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "Â· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">BUPTyqx&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">BUPTyqx&#39;s Blog</a><a id="mobile-toggle-theme">Â·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6; // ä¸º 6 æ—¶å±•å¼€æ‰€æœ‰
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function() {
            tocbot.refresh(obj_merge(tocbot_default_config, {
                hasInnerContainers: true
            }));
        }, 420); // è¿™ä¸ªå€¼æ˜¯ç”± tocbot æºç é‡Œå®šä¹‰çš„ scrollSmoothDuration å¾—æ¥çš„
    }

    document.ready(function() {
        tocbot.init(obj_merge(tocbot_default_config, {
            collapseDepth: 1
        }));
    });

    function expand_toc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, {
            collapseDepth: expanded ? 1 : DEPTH_MAX
        }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">pytorchæ—¥ç§¯æœˆç´¯-æŸå¤±å‡½æ•°</h1>
            
                <div class="post-meta">
                    
                        ğŸ¦¹â€â™€ï¸ä½œè€…: <a itemprop="author" rel="author" href="/">å°¹ç¥ºç¿”</a><br>
                    

                    
                        <span class="post-time">
                        â²ï¸æ—¶é—´: <a href="#">June 30, 2022&nbsp;&nbsp;2:26:51</a><br>
                        </span>
                    
                    
                        <span class="post-category">
                            ğŸ“’ç›®å½•:
                            
                                <a href="/categories/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF/">pytorchæ—¥ç§¯æœˆç´¯</a><br>
                            
                        </span>
                    
                    
                    
                        <span class="post-count">
                            ğŸ“‘å­—æ•°:
                        <a href="">1,531</a><br>  
                        </span>
                    
                    
                        <span class="post-count">
                    â°é¢„è®¡é˜…è¯»æ—¶é—´:
                        <a href="">8min</a>  
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="pytorchæ—¥ç§¯æœˆç´¯9-æŸå¤±å‡½æ•°"><a href="#pytorchæ—¥ç§¯æœˆç´¯9-æŸå¤±å‡½æ•°" class="headerlink" title="pytorchæ—¥ç§¯æœˆç´¯9-æŸå¤±å‡½æ•°"></a>pytorchæ—¥ç§¯æœˆç´¯9-æŸå¤±å‡½æ•°</h1><p><strong>æŸå¤±å‡½æ•°ï¼šè¡¡é‡æ¨¡å‹è¾“å‡ºä¸çœŸå®æ ‡ç­¾çš„å·®å¼‚</strong></p>
<p><img src="/2022/06/30/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF9-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/image-20200821113843119.png" alt="image-20200821113843119" style="zoom:38%;"></p>
<p><strong>æŸå¤±å‡½æ•°(Loss Function)ï¼š</strong></p>
<script type="math/tex; mode=display">
\operatorname{Loss} =f\left(\hat{y}, y\right)</script><p><strong>ä»£ä»·å‡½æ•°(Cost Function)ï¼š</strong></p>
<script type="math/tex; mode=display">
\cos t=\frac{1}{N} \sum_{i}^{N} f\left(\hat{y_{i}}, y_{i}\right)</script><p><strong>ç›®æ ‡å‡½æ•°(Objective Function)ï¼š</strong></p>
<script type="math/tex; mode=display">
 \boldsymbol{O} \boldsymbol{b} \boldsymbol{j}=  Cost  +  Regularization</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">_Loss</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">'mean'</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(_Loss, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> size_average <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">or</span> reduce <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.reduction = _Reduction.legacy_get_string(</span><br><span class="line">                            size_average, reduce)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.reduction = reduction</span><br></pre></td></tr></tbody></table></figure>
<h2 id="1-äº¤å‰ç†µæŸå¤±å‡½æ•°"><a href="#1-äº¤å‰ç†µæŸå¤±å‡½æ•°" class="headerlink" title="1.äº¤å‰ç†µæŸå¤±å‡½æ•°"></a>1.äº¤å‰ç†µæŸå¤±å‡½æ•°</h2><p>åŠŸèƒ½ï¼š nn.LogSoftmax ()ä¸nn.NLLLoss ()ç»“åˆï¼Œè¿›è¡Œäº¤å‰ç†µè®¡ç®—</p>
<p>ä¸»è¦å‚æ•°ï¼š</p>
<ul>
<li><p>weight<strong>ï¼šå„ç±»åˆ«çš„lossè®¾ç½®æƒå€¼</strong></p>
</li>
<li><p>ignore _index<strong>ï¼šå¿½ç•¥æŸä¸ªç±»åˆ«</strong></p>
</li>
<li><p>reduction ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸ºnone/sum /mean</p>
<ul>
<li>none- é€ä¸ªå…ƒç´ è®¡ç®—</li>
<li>sum- æ‰€æœ‰å…ƒç´ æ±‚å’Œï¼Œè¿”å›æ ‡é‡</li>
<li>mean- åŠ æƒå¹³å‡ï¼Œè¿”å›æ ‡é‡</li>
</ul>
</li>
</ul>
<p>ç†µï¼š</p>
<script type="math/tex; mode=display">
\mathrm{H}(\mathrm{P})=E_{x \sim p}[I(x)]=-\sum_{i}^{N} P\left(x_{i}\right) \log P\left(x_{i}\right)</script><p>è‡ªä¿¡æ¯ï¼š</p>
<script type="math/tex; mode=display">
I(x)=-\log [p(x)]</script><p>ç›¸å¯¹ç†µï¼š</p>
<script type="math/tex; mode=display">
\begin{aligned}
D_{K L}(P, Q) &=E_{x \sim p}\left[\log \frac{P(x)}{Q(x)}\right] \\
&=E_{x \sim p}[\log P(x)-\log Q(x)] \\
&=\sum_{i=1}^{N} P\left(x_{i}\right)\left[\log P\left(x_{i}\right)-\log Q\left(x_{i}\right)\right] \\
&=\sum_{i=1}^{N} P\left(x_{i}\right) \log P\left(x_{i}\right)-\sum_{i=1}^{N} P\left(x_{i}\right) \log Q\left(x_{i}\right) \\
&=H(P, Q)-H(\mathrm{P})
\end{aligned}</script><p>äº¤å‰ç†µï¼š</p>
<script type="math/tex; mode=display">
\mathrm{H}(\boldsymbol{P}, \boldsymbol{Q})=\boldsymbol{D}_{K L}(\boldsymbol{P}, \boldsymbol{Q})+\mathrm{H}(\boldsymbol{P})</script><script type="math/tex; mode=display">
\mathrm{H}(\boldsymbol{P}, \boldsymbol{Q})=-\sum_{i=1}^{N} \boldsymbol{P}\left(\boldsymbol{x}_{i}\right) \log Q\left(\boldsymbol{x}_{i}\right)</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">nn.CrossEntropyLoss(weight=<span class="literal">None</span>, <span class="comment">#å„ç±»åˆ«çš„lossè®¾ç½®æƒå€¼</span></span><br><span class="line">                    size_average=<span class="literal">None</span>, </span><br><span class="line">                    ignore_index=-<span class="number">100</span>,<span class="comment">#å¿½ç•¥æŸä¸€ä¸ªç±»åˆ« </span></span><br><span class="line">                    reduce=<span class="literal">None</span>, </span><br><span class="line">                    reduction=â€˜meanâ€™)<span class="comment">#è®¡ç®—æ¨¡å¼</span></span><br><span class="line"><span class="comment">#none-é€å…ƒç´ è®¡ç®—</span></span><br><span class="line"><span class="comment">#sum-æ‰€æœ‰å…ƒç´ æ±‚å’Œè¿”å›æ ‡é‡</span></span><br><span class="line"><span class="comment">#mean-åŠ æƒå¹³å‡ï¼Œè¿”å›æ ‡é‡</span></span><br></pre></td></tr></tbody></table></figure>
<script type="math/tex; mode=display">
\mathrm{H}(\boldsymbol{P}, \boldsymbol{Q})=-\sum_{\boldsymbol{i}=1}^{N} \boldsymbol{P}\left(\boldsymbol{x}_{\boldsymbol{i}}\right) \log \boldsymbol{Q}\left(\boldsymbol{x}_{\boldsymbol{i}}\right) \\
\operatorname{loss}(x, \text {class})=-\log \left(\frac{\exp (x[\operatorname{class}])}{\sum_{j} \exp (x[j])}\right)=-x[\operatorname{class}]+\log \left(\sum_{j} \exp (x[j])\right) \\
\operatorname{loss}(x, \text {class})=\text { weight[class] }\left(-x[\text { class }]+\log \left(\sum_{j} \exp (x[j])\right)\right)</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># def loss function</span></span><br><span class="line">loss_f_none = nn.CrossEntropyLoss(weight=<span class="literal">None</span>, reduction=<span class="string">'none'</span>)</span><br><span class="line"><span class="comment"># forward</span></span><br><span class="line">loss_none = loss_f_none(inputs, target)</span><br><span class="line"><span class="comment"># view</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Cross Entropy Loss:\n "</span>, loss_none, loss_sum, loss_mean)</span><br><span class="line"><span class="comment">#å®ç°åŸç†:</span></span><br><span class="line">    idx = <span class="number">0</span></span><br><span class="line">    input_1 = inputs.detach().numpy()[idx]      <span class="comment"># [1, 2]</span></span><br><span class="line">    target_1 = target.numpy()[idx]              <span class="comment"># [0]</span></span><br><span class="line">    <span class="comment"># ç¬¬ä¸€é¡¹</span></span><br><span class="line">    x_class = input_1[target_1]</span><br><span class="line">    <span class="comment"># ç¬¬äºŒé¡¹</span></span><br><span class="line">    sigma_exp_x = np.<span class="built_in">sum</span>(<span class="built_in">list</span>(<span class="built_in">map</span>(np.exp, input_1)))</span><br><span class="line">    log_sigma_exp_x = np.log(sigma_exp_x)</span><br><span class="line">    <span class="comment"># è¾“å‡ºloss</span></span><br><span class="line">    loss_1 = -x_class + log_sigma_exp_x</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"ç¬¬ä¸€ä¸ªæ ·æœ¬lossä¸º: "</span>, loss_1)</span><br><span class="line"><span class="comment">#å¸¦æƒå€¼ï¼š</span></span><br><span class="line">weights = torch.tensor([<span class="number">1</span>, <span class="number">2</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">loss_f_none_w = nn.CrossEntropyLoss(weight=weights, reduction=<span class="string">'none'</span>)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="2-NLLLoss"><a href="#2-NLLLoss" class="headerlink" title="2.NLLLoss"></a>2.NLLLoss</h2><p>åŠŸèƒ½ï¼šå®ç°è´Ÿå¯¹æ•°ä¼¼ç„¶å‡½æ•°ä¸­çš„è´Ÿå·åŠŸèƒ½</p>
<script type="math/tex; mode=display">
\ell(x, y)=L=\left\{l_{1}, \ldots, l_{N}\right\}^{\prime}, \quad l_{n}=-w_{y_{n}} x_{n, y_{n}}</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nn.NLLLoss( weight=<span class="literal">None</span>,</span><br><span class="line">            size_average=<span class="literal">None</span>, </span><br><span class="line">            ignore_index=-<span class="number">100</span>, </span><br><span class="line">            reduce=<span class="literal">None</span>, </span><br><span class="line">            reduction=<span class="string">'mean'</span>)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="3-BCELoss"><a href="#3-BCELoss" class="headerlink" title="3.BCELoss"></a>3.BCELoss</h2><p>åŠŸèƒ½ï¼šäºŒåˆ†ç±»äº¤å‰ç†µ<br>æ³¨æ„äº‹é¡¹ï¼šè¾“å…¥å€¼å–å€¼åœ¨[0,1]<br>ä¸»è¦å‚æ•°ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nn.BCELoss( weight=<span class="literal">None</span>, </span><br><span class="line">            size_average=<span class="literal">None</span>, </span><br><span class="line">            reduce=<span class="literal">None</span>, </span><br><span class="line">            reduction=<span class="string">'mean'</span>)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">5</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">target = torch.tensor([[<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">target_bce = target</span><br><span class="line"><span class="comment"># itarget</span></span><br><span class="line">inputs = torch.sigmoid(inputs)</span><br><span class="line">weights = torch.tensor([<span class="number">1</span>, <span class="number">1</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">loss_f_none_w = nn.BCELoss(weight=weights, reduction=<span class="string">'none'</span>)</span><br><span class="line"><span class="comment"># forward</span></span><br><span class="line">loss_none_w = loss_f_none_w(inputs, target_bce)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="4-BCEWithLogitsLoss"><a href="#4-BCEWithLogitsLoss" class="headerlink" title="4.BCEWithLogitsLoss"></a>4.BCEWithLogitsLoss</h2><p>åŠŸèƒ½ï¼šç»“åˆSigmoidä¸äºŒåˆ†ç±»äº¤å‰ç†µ</p>
<p>æ³¨æ„äº‹é¡¹ï¼šç½‘ç»œæœ€åä¸åŠ sigmoidå‡½æ•°</p>
<script type="math/tex; mode=display">
l_{n}=-w_{n}\left[y_{n} \cdot \log \sigma\left(x_{n}\right)+\left(1-y_{n}\right) \cdot \log \left(1-\sigma\left(x_{n}\right)\right)\right]</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nn.BCEWithLogitsLoss(weight=<span class="literal">None</span>, </span><br><span class="line">                    size_average=<span class="literal">None</span>, </span><br><span class="line">                    reduce=<span class="literal">None</span>, </span><br><span class="line">                    reduction=<span class="string">'mean'</span>, </span><br><span class="line">                    pos_weight=<span class="literal">None</span>)<span class="comment">#æ­£æ ·æœ¬çš„æƒå€¼</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">5</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">target = torch.tensor([[<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">target_bce = target</span><br><span class="line">weights = torch.tensor([<span class="number">1</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">pos_w = torch.tensor([<span class="number">3</span>], dtype=torch.<span class="built_in">float</span>)        <span class="comment"># 3</span></span><br><span class="line">loss_f_none_w = nn.BCEWithLogitsLoss(weight=weights, reduction=<span class="string">'none'</span>, </span><br><span class="line">                                     pos_weight=pos_w)</span><br><span class="line">loss_none_w = loss_f_none_w(inputs, target_bce)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="5-nn-L1Loss"><a href="#5-nn-L1Loss" class="headerlink" title="5.nn.L1Loss"></a>5.nn.L1Loss</h2><p><strong>åŠŸèƒ½ï¼š</strong> <strong>è®¡ç®—inputsä¸targetä¹‹å·®çš„ç»å¯¹å€¼</strong></p>
<script type="math/tex; mode=display">
l_{n}=\left|x_{n}-y_{n}\right|</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nn.L1Loss(size_average=<span class="literal">None</span>, </span><br><span class="line">          reduce=<span class="literal">None</span>, </span><br><span class="line">          reduction=<span class="string">'meanâ€™)</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="6-nn-MSELoss"><a href="#6-nn-MSELoss" class="headerlink" title="6.nn.MSELoss"></a>6.nn.MSELoss</h2><p><strong>åŠŸèƒ½ï¼š</strong> <strong>è®¡ç®—inputsä¸targetä¹‹å·®çš„å¹³æ–¹</strong></p>
<script type="math/tex; mode=display">
l_{n}=\left(x_{n}-y_{n}\right)^{2}</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nn.MSELoss(size_average=<span class="literal">None</span>, </span><br><span class="line">           reduce=<span class="literal">None</span>, </span><br><span class="line">           reduction=<span class="string">'meanâ€™)</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="7-SmoothL1Loss"><a href="#7-SmoothL1Loss" class="headerlink" title="7.SmoothL1Loss"></a>7.SmoothL1Loss</h2><p><strong>åŠŸèƒ½ï¼š</strong> <strong>å¹³æ»‘çš„L1Loss</strong></p>
<p><img src="/2022/06/30/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF9-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/image-20200821160415861.png" alt="image-20200821160415861" style="zoom:100%;"></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nn.SmoothL1Loss(size_average=<span class="literal">None</span>, </span><br><span class="line">                reduce=<span class="literal">None</span>, </span><br><span class="line">                reduction=<span class="string">'meanâ€™)</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="8-PoissonNLLLoss"><a href="#8-PoissonNLLLoss" class="headerlink" title="8.PoissonNLLLoss"></a>8.PoissonNLLLoss</h2><p><strong>åŠŸèƒ½ï¼šæ³Šæ¾åˆ†å¸ƒçš„è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±å‡½æ•°</strong></p>
<ul>
<li><p><code>log_input = Trueï¼šloss(input, target) = exp(input) - target * input</code></p>
</li>
<li><p><code>log_input = Falseï¼šloss(input, target) = input - target * log(input+eps)</code></p>
</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">nn.PoissonNLLLoss(log_input=<span class="literal">True</span>, <span class="comment">#log_inputï¼šè¾“å…¥æ˜¯å¦ä¸ºå¯¹æ•°å½¢å¼ï¼Œå†³å®šè®¡ç®—å…¬å¼</span></span><br><span class="line">                  full=<span class="literal">False</span>, <span class="comment">#fullï¼šè®¡ç®—æ‰€æœ‰lossï¼Œé»˜è®¤ä¸ºFalse</span></span><br><span class="line">                  size_average=<span class="literal">None</span>, </span><br><span class="line">                  eps=<span class="number">1e-08</span>,<span class="comment">#epsï¼šä¿®æ­£é¡¹ï¼Œé¿å…logï¼ˆinputï¼‰ä¸ºnan*</span></span><br><span class="line">                  reduce=<span class="literal">None</span>, </span><br><span class="line">                  reduction=<span class="string">'mean'</span>)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="9-nn-KLDivLoss"><a href="#9-nn-KLDivLoss" class="headerlink" title="9.nn.KLDivLoss"></a>9.nn.KLDivLoss</h2><p>åŠŸèƒ½ï¼šè®¡ç®—KLDï¼ˆdivergenceï¼‰ï¼ŒKLæ•£åº¦ï¼Œç›¸å¯¹ç†µ</p>
<p>æ³¨æ„äº‹é¡¹ï¼šéœ€æå‰å°†è¾“å…¥è®¡ç®— log-probabilitiesï¼Œå¦‚é€šè¿‡nn.logsoftmax()</p>
<script type="math/tex; mode=display">
D_{K L}(P \| Q)=E_{x \sim p}\left[\log \frac{P(x)}{Q(x)}\right]=E_{x-p}[\log P(x)-\log Q(x)] \\
=\sum_{i=1}^{N} P\left(x_{i}\right)\left(\log P\left(x_{i}\right)-\log Q\left(x_{i}\right)\right) \\
l_{n}=y_{n} \cdot\left(\log y_{n}-x_{n}\right)</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nn.KLDivLoss(size_average=<span class="literal">None</span>, </span><br><span class="line">             reduce=<span class="literal">None</span>, </span><br><span class="line">             reduction=<span class="string">'mean'</span>)</span><br><span class="line"><span class="comment">#reduction ï¼šnone/sum/mean/batchmean</span></span><br><span class="line"><span class="comment">#batchmean- batchsizeç»´åº¦æ±‚å¹³å‡å€¼</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.tensor([[<span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.2</span>], [<span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.5</span>]])</span><br><span class="line">inputs_log = torch.log(inputs)</span><br><span class="line">target = torch.tensor([[<span class="number">0.9</span>, <span class="number">0.05</span>, <span class="number">0.05</span>], [<span class="number">0.1</span>, <span class="number">0.7</span>, <span class="number">0.2</span>]], </span><br><span class="line">                      dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">loss_f_bs_mean = nn.KLDivLoss(reduction=<span class="string">'batchmean'</span>)</span><br><span class="line">loss_bs_mean = loss_f_bs_mean(inputs, target)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="10-nn-MarginRankingLoss"><a href="#10-nn-MarginRankingLoss" class="headerlink" title="10.nn.MarginRankingLoss"></a>10.nn.MarginRankingLoss</h2><p>åŠŸèƒ½ï¼š<strong>è®¡ç®—ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œç”¨äºæ’åºä»»åŠ¡</strong></p>
<p>ç‰¹åˆ«è¯´æ˜ï¼šè¯¥æ–¹æ³•è®¡ç®—ä¸¤ç»„æ•°æ®ä¹‹é—´çš„å·®å¼‚ï¼Œè¿”å›ä¸€ä¸ª<script type="math/tex">n\times n</script>çš„ loss çŸ©é˜µ</p>
<script type="math/tex; mode=display">
\operatorname{loss}(x, y)=\max (0,-y \times(x_ 1-x _2)+\operatorname{margin})</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">nn.MarginRankingLoss(margin=<span class="number">0.0</span>, <span class="comment">#margin ï¼šè¾¹ç•Œå€¼ï¼Œx1ä¸x2ä¹‹é—´çš„å·®å¼‚å€¼</span></span><br><span class="line">                     size_average=<span class="literal">None</span>, </span><br><span class="line">                     reduce=<span class="literal">None</span>, </span><br><span class="line">                     reduction=<span class="string">'mean'</span>)<span class="comment">#reduction ï¼šè®¡ç®—æ¨¡å¼ï¼Œå¯ä¸ºnone/sum/mean</span></span><br><span class="line"><span class="comment">#y = 1æ—¶ï¼Œ å¸Œæœ›x1æ¯”x2å¤§ï¼Œå½“x1&gt;x2æ—¶ï¼Œä¸äº§ç”Ÿloss</span></span><br><span class="line"><span class="comment">#y = -1æ—¶ï¼Œå¸Œæœ›x2æ¯”x1å¤§ï¼Œå½“x2&gt;x1æ—¶ï¼Œä¸äº§ç”Ÿloss</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x1 = torch.tensor([[<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">x2 = torch.tensor([[<span class="number">2</span>], [<span class="number">2</span>], [<span class="number">2</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">target = torch.tensor([<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">loss_f_none = nn.MarginRankingLoss(margin=<span class="number">0</span>, reduction=<span class="string">'none'</span>)</span><br><span class="line">loss = loss_f_none(x1, x2, target)</span><br><span class="line"><span class="built_in">print</span>(loss)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="11-nn-MultiLabelMarginLoss"><a href="#11-nn-MultiLabelMarginLoss" class="headerlink" title="11.nn.MultiLabelMarginLoss"></a>11.nn.MultiLabelMarginLoss</h2><p>åŠŸèƒ½ï¼š<strong>å¤šæ ‡ç­¾è¾¹ç•ŒæŸå¤±å‡½æ•°</strong></p>
<p>ä¸¾ä¾‹ï¼šå››åˆ†ç±»ä»»åŠ¡ï¼Œæ ·æœ¬xå±äº0ç±»å’Œ3ç±»ï¼Œæ ‡ç­¾ï¼š[0, 3, -1, -1] , ä¸æ˜¯[1, 0, 0, 1]</p>
<p><img src="/2022/06/30/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF9-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/image-20200821161750301.png" alt="image-20200821161750301" style="zoom:100%;"></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nn.MultiLabelMarginLoss(</span><br><span class="line">    size_average=<span class="literal">None</span>, </span><br><span class="line">    reduce=<span class="literal">None</span>, </span><br><span class="line">    reduction=<span class="string">'mean'</span>)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([[<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.8</span>]])</span><br><span class="line">y = torch.tensor([[<span class="number">0</span>, <span class="number">3</span>, -<span class="number">1</span>, -<span class="number">1</span>]], dtype=torch.long)</span><br><span class="line">loss_f = nn.MultiLabelMarginLoss(reduction=<span class="string">'none'</span>)</span><br><span class="line">loss = loss_f(x, y)</span><br><span class="line"><span class="comment">#ä¸‹é¢æ˜¯æ‰‹åŠ¨è®¡ç®—çš„ä»£ç </span></span><br><span class="line">x = x[<span class="number">0</span>]</span><br><span class="line">item_1 = (<span class="number">1</span>-(x[<span class="number">0</span>] - x[<span class="number">1</span>])) + (<span class="number">1</span> - (x[<span class="number">0</span>] - x[<span class="number">2</span>]))    <span class="comment"># [0]</span></span><br><span class="line">item_2 = (<span class="number">1</span>-(x[<span class="number">3</span>] - x[<span class="number">1</span>])) + (<span class="number">1</span> - (x[<span class="number">3</span>] - x[<span class="number">2</span>]))    <span class="comment"># [3]</span></span><br><span class="line">loss_h = (item_1 + item_2) / x.shape[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(loss_h)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="12-nn-SoftMarginLoss"><a href="#12-nn-SoftMarginLoss" class="headerlink" title="12.nn.SoftMarginLoss"></a>12.nn.SoftMarginLoss</h2><p>åŠŸèƒ½ï¼šè®¡ç®—äºŒåˆ†ç±»çš„logisticæŸå¤±</p>
<script type="math/tex; mode=display">
\operatorname{loss}(x, y)=\sum_{i} \frac{\log (1+\exp (-y[i] \times x[i]))}{\text { x.nelement }()}</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nn.SoftMarginLoss(size_average=<span class="literal">None</span>, </span><br><span class="line">                  reduce=<span class="literal">None</span>, </span><br><span class="line">                  reduction=<span class="string">'mean'</span>)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="13-nn-MultiLabelSoftMarginLoss"><a href="#13-nn-MultiLabelSoftMarginLoss" class="headerlink" title="13.nn.MultiLabelSoftMarginLoss"></a>13.nn.MultiLabelSoftMarginLoss</h2><p>åŠŸèƒ½ï¼šSoftMarginLosså¤šæ ‡ç­¾ç‰ˆæœ¬</p>
<script type="math/tex; mode=display">
\operatorname{los} s(x, y)=-\frac{1}{C} * \sum_{i} y[i] * \log \left((1+\exp (-x[i]))^{-1}\right)+(1-y[i]) * \log \left(\frac{\exp (-x[i])}{(1+\exp (-x[i]))}\right)</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nn.MultiLabelSoftMarginLoss(weight=<span class="literal">None</span>, </span><br><span class="line">                            size_average=<span class="literal">None</span>, </span><br><span class="line">                            reduce=<span class="literal">None</span>, </span><br><span class="line">                            reduction=<span class="string">'mean'</span>)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="14-nn-MultiMarginLoss"><a href="#14-nn-MultiMarginLoss" class="headerlink" title="14.nn.MultiMarginLoss"></a>14.nn.MultiMarginLoss</h2><p>åŠŸèƒ½ï¼šè®¡ç®—å¤šåˆ†ç±»çš„æŠ˜é¡µæŸå¤±</p>
<script type="math/tex; mode=display">
\operatorname{loss}(x, y)=\frac{\left.\sum_{i} \max (0, \operatorname{margin}-x[y]+x[i])\right)^{p}}{x . \operatorname{size}(0)}</script><p><img src="/2022/06/30/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF9-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/image-20200821162352276.png" alt="image-20200821162352276"></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">nn.MultiMarginLoss(p=<span class="number">1</span>, <span class="comment">#å¯é€‰å‚æ•°1æˆ–2</span></span><br><span class="line">                   margin=<span class="number">1.0</span>, <span class="comment">#è¾¹ç•Œå€¼</span></span><br><span class="line">                   weight=<span class="literal">None</span>, <span class="comment">#å„ç±»åˆ«çš„lossè®¾ç½®æƒå€¼</span></span><br><span class="line">                   size_average=<span class="literal">None</span>, </span><br><span class="line">                   reduce=<span class="literal">None</span>, </span><br><span class="line">                   reduction=<span class="string">'mean'</span>)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="15-nn-TripletMarginLoss"><a href="#15-nn-TripletMarginLoss" class="headerlink" title="15.nn.TripletMarginLoss"></a>15.nn.TripletMarginLoss</h2><p>åŠŸèƒ½ï¼šè®¡ç®—ä¸‰å…ƒç»„æŸå¤±ï¼Œäººè„¸éªŒè¯ä¸­å¸¸ç”¨</p>
<script type="math/tex; mode=display">
\begin{array}{c}
L(a, p, n)=\max \left\{d\left(a_{i}, p_{i}\right)-d\left(a_{i}, n_{i}\right)+\operatorname{margin}, 0\right\} \\
\qquad d\left(x_{i}, y_{i}\right)=\left\|\mathbf{x}_{i}-\mathbf{y}_{i}\right\|_{p}
\end{array}</script><p><img src="/2022/06/30/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF9-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/image-20200821162803647.png" alt="image-20200821162803647" style="zoom:100%;"></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">nn.TripletMarginLoss(margin=<span class="number">1.0</span>, </span><br><span class="line">                     p=<span class="number">2.0</span>, </span><br><span class="line">                     eps=<span class="number">1e-06</span>, </span><br><span class="line">                     swap=<span class="literal">False</span>, </span><br><span class="line">                     size_average=<span class="literal">None</span>, </span><br><span class="line">                     reduce=<span class="literal">None</span>, </span><br><span class="line">                     reduction=<span class="string">'mean'</span>)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="16-nn-HingeEmbeddingLoss"><a href="#16-nn-HingeEmbeddingLoss" class="headerlink" title="16.nn.HingeEmbeddingLoss"></a>16.nn.HingeEmbeddingLoss</h2><p>åŠŸèƒ½ï¼šè®¡ç®—ä¸¤ä¸ªè¾“å…¥çš„ç›¸ä¼¼æ€§ï¼Œå¸¸ç”¨äºéçº¿æ€§embeddingå’ŒåŠç›‘ç£å­¦ä¹ </p>
<p>ç‰¹åˆ«æ³¨æ„ï¼šè¾“å…¥xåº”ä¸ºä¸¤ä¸ªè¾“å…¥ä¹‹å·®çš„ç»å¯¹å€¼ã€‚</p>
<script type="math/tex; mode=display">
l_{n}=\left\{\begin{array}{ll}
x_{n}, & \text { if } y_{n}=1 \\
\max \left\{0, \Delta-x_{n}\right\}, & \text { if } y_{n}=-1
\end{array}\right.</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nn.HingeEmbeddingLoss(margin=<span class="number">1.0</span>, </span><br><span class="line">                      size_average=<span class="literal">None</span>, </span><br><span class="line">                      reduce=<span class="literal">None</span>, </span><br><span class="line">                      reduction=<span class="string">'meanâ€™)</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.tensor([[<span class="number">1.</span>, <span class="number">0.8</span>, <span class="number">0.5</span>]])</span><br><span class="line">target = torch.tensor([[<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>]])</span><br><span class="line">loss_f = nn.HingeEmbeddingLoss(margin=<span class="number">1</span>, reduction=<span class="string">'none'</span>)</span><br><span class="line">loss = loss_f(inputs, target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Hinge Embedding Loss"</span>, loss)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="17-nn-CosineEmbeddingLoss"><a href="#17-nn-CosineEmbeddingLoss" class="headerlink" title="17.nn.CosineEmbeddingLoss"></a>17.nn.CosineEmbeddingLoss</h2><p>åŠŸèƒ½:é‡‡ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—ä¸¤ä¸ªè¾“å…¥çš„ç›¸ä¼¼æ€§</p>
<script type="math/tex; mode=display">
\operatorname{loss}(x, y)=\left\{\begin{array}{ll}
1-\cos \left(x_{1}, x_{2}\right), & \text { if } y=1 \\
\max \left(0, \cos \left(x_{1}, x_{2}\right)-\operatorname{margin}\right), & \text { if } y=-1
\end{array}\right. \\
\cos (\theta)=\frac{A \cdot B}{\|A\|\|B\|}=\frac{\sum_{i=1}^{n} A_{i} \times B_{i}}{\sqrt{\sum_{i=1}^{n}\left(A_{i}\right)^{2}} \times \sqrt{\sum_{i=1}^{n}\left(B_{i}\right)^{2}}}</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nn.CosineEmbeddingLoss(margin=<span class="number">0.0</span>, <span class="comment">#å¯å–å€¼[-1, 1] , æ¨èä¸º[0, 0.5]</span></span><br><span class="line">                       size_average=<span class="literal">None</span>, </span><br><span class="line">                       reduce=<span class="literal">None</span>, </span><br><span class="line">                       reduction=<span class="string">'mean'</span>)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="18-nn-CTCLoss"><a href="#18-nn-CTCLoss" class="headerlink" title="18.nn.CTCLoss"></a>18.nn.CTCLoss</h2><p>åŠŸèƒ½ï¼š è®¡ç®—CTCæŸå¤±ï¼Œè§£å†³æ—¶åºç±»æ•°æ®çš„åˆ†ç±»</p>
<p>Connectionist Temporal Classification</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.CTCLoss(blank=<span class="number">0</span>, </span><br><span class="line">                 reduction=<span class="string">'mean'</span>, </span><br><span class="line">                 zero_infinity=<span class="literal">False</span>)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/06/30/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF9-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/image-20200821163417976.png" alt="image-20200821163417976" style="zoom: 100%;"></p>

        </div>

        
            <section class="post-copyright">
                
                
                
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E7%BC%96%E7%A8%8B/">ğŸ·ï¸ç¼–ç¨‹</a>
                    
                        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">ğŸ·ï¸æ·±åº¦å­¦ä¹ </a>
                    
                        <a href="/tags/Pytorch/">ğŸ·ï¸Pytorch</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>Â· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2022/06/30/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF10-%E4%BC%98%E5%8C%96%E5%99%A8/">pytorchæ—¥ç§¯æœˆç´¯-ä¼˜åŒ–å™¨</a>
            
            
            <a class="next" rel="next" href="/2022/06/30/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF8-%E6%9D%83%E5%80%BC%E5%88%9D%E5%A7%8B%E5%8C%96/">pytorchæ—¥ç§¯æœˆç´¯-æƒå€¼åˆå§‹åŒ–</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>Â© å°¹ç¥ºç¿” | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>

</html>