<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="å°¹ç¥ºç¿”">





<title>pytorchæ—¥ç§¯æœˆç´¯-æ¢¯åº¦ä¸è‡ªåŠ¨æ±‚å¯¼ | yqxBlog</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
            <!-- MathJaxé…ç½®ï¼Œå¯é€šè¿‡å•ç¾å…ƒç¬¦å·ä¹¦å†™è¡Œå†…å…¬å¼ç­‰ -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- ç»™MathJaxå…ƒç´ æ·»åŠ has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- é€šè¿‡è¿æ¥CDNåŠ è½½MathJaxçš„jsä»£ç  -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<meta name="generator" content="Hexo 5.4.2">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "Â· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "Â· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">BUPTyqx&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">BUPTyqx&#39;s Blog</a><a id="mobile-toggle-theme">Â·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6; // ä¸º 6 æ—¶å±•å¼€æ‰€æœ‰
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function() {
            tocbot.refresh(obj_merge(tocbot_default_config, {
                hasInnerContainers: true
            }));
        }, 420); // è¿™ä¸ªå€¼æ˜¯ç”± tocbot æºç é‡Œå®šä¹‰çš„ scrollSmoothDuration å¾—æ¥çš„
    }

    document.ready(function() {
        tocbot.init(obj_merge(tocbot_default_config, {
            collapseDepth: 1
        }));
    });

    function expand_toc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, {
            collapseDepth: expanded ? 1 : DEPTH_MAX
        }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">pytorchæ—¥ç§¯æœˆç´¯-æ¢¯åº¦ä¸è‡ªåŠ¨æ±‚å¯¼</h1>
            
                <div class="post-meta">
                    
                        ğŸ¦¹â€â™€ï¸ä½œè€…: <a itemprop="author" rel="author" href="/">å°¹ç¥ºç¿”</a><br>
                    

                    
                        <span class="post-time">
                        â²ï¸æ—¶é—´: <a href="#">June 29, 2022&nbsp;&nbsp;14:19:39</a><br>
                        </span>
                    
                    
                        <span class="post-category">
                            ğŸ“’ç›®å½•:
                            
                                <a href="/categories/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF/">pytorchæ—¥ç§¯æœˆç´¯</a><br>
                            
                        </span>
                    
                    
                    
                        <span class="post-count">
                            ğŸ“‘å­—æ•°:
                        <a href="">1,606</a><br>  
                        </span>
                    
                    
                        <span class="post-count">
                    â°é¢„è®¡é˜…è¯»æ—¶é—´:
                        <a href="">8min</a>  
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="pytorchæ—¥ç§¯æœˆç´¯4-æ¢¯åº¦ä¸è‡ªåŠ¨æ±‚å¯¼"><a href="#pytorchæ—¥ç§¯æœˆç´¯4-æ¢¯åº¦ä¸è‡ªåŠ¨æ±‚å¯¼" class="headerlink" title="pytorchæ—¥ç§¯æœˆç´¯4-æ¢¯åº¦ä¸è‡ªåŠ¨æ±‚å¯¼"></a>pytorchæ—¥ç§¯æœˆç´¯4-æ¢¯åº¦ä¸è‡ªåŠ¨æ±‚å¯¼</h1><h2 id="1-æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒâ€”â€”æ¢¯åº¦"><a href="#1-æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒâ€”â€”æ¢¯åº¦" class="headerlink" title="1.æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒâ€”â€”æ¢¯åº¦"></a>1.æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒâ€”â€”æ¢¯åº¦</h2><p><img src="/2022/06/29/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF4-%E6%A2%AF%E5%BA%A6%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/image-20200721124255052.png" alt="image-20200721124255052"></p>
<p>learnrateï¼šå­¦ä¹ ç‡ï¼Œè¿­ä»£é€Ÿåº¦çš„é™åˆ¶å› ç´ ã€‚</p>
<p>è®¾ç½®ä¸åŒçš„æ¢¯åº¦ä¸‹é™çš„æ±‚è§£å™¨</p>
<script type="math/tex; mode=display">
loss=(WX+b-y)^2\\
w'=w-lr\times \frac{\bigtriangledown loss }{\bigtriangledown w}</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_error_for_line_given_points</span>(<span class="params">b,w,points</span>):</span><br><span class="line">    totalError=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(points)):</span><br><span class="line">        x=points[i,<span class="number">0</span>]<span class="comment">#å–xå€¼</span></span><br><span class="line">        y=points[i,<span class="number">1</span>]<span class="comment">#å–yå€¼</span></span><br><span class="line">        totalError+=(y-(w*x+b))**<span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> totalError/<span class="built_in">float</span>(<span class="built_in">len</span>(points))<span class="comment">#åšå¹³å‡</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">step_gradient</span>(<span class="params">b_current,w_current,points,learningRate</span>):</span><br><span class="line">    b_gradient=<span class="number">0</span></span><br><span class="line">    w_gradient=<span class="number">0</span></span><br><span class="line">    N=<span class="built_in">float</span>(<span class="built_in">len</span>(points))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(points)):</span><br><span class="line">        x = points[i, <span class="number">0</span>]  <span class="comment"># å–xå€¼</span></span><br><span class="line">        y = points[i, <span class="number">1</span>]  <span class="comment"># å–yå€¼</span></span><br><span class="line">        <span class="comment">#é€šè¿‡æ•°å­¦æ–¹æ³•è®¡ç®—å‡ºæ±‚å¯¼å…¬å¼ï¼Œç„¶åä»£å…¥è®¡ç®—ã€‚</span></span><br><span class="line">        b_gradient+=-(<span class="number">2</span>/N)*(y-((w_current*x)+b_current))<span class="comment">#å¯¹bæ±‚å¯¼</span></span><br><span class="line">        w_gradient+=-(<span class="number">2</span>/N)*x*(y-((w_current*x)+b_current))<span class="comment">#å¯¹wæ±‚å¯¼</span></span><br><span class="line">    new_b=b_current-(learningRate*b_gradient)</span><br><span class="line">    new_w=w_current-(learningRate*w_gradient)</span><br><span class="line">    <span class="keyword">return</span> [new_b,new_w]</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_descent_runner</span>(<span class="params">points,starting_b,starting_w,</span></span><br><span class="line"><span class="params">                            learing_rate,num_iterations</span>):</span><br><span class="line">    b=starting_b</span><br><span class="line">    w=starting_w</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_iterations):</span><br><span class="line">        b,m=step_gradient(b,w,np.array(points),learing_rate)</span><br><span class="line">    <span class="keyword">return</span> [b,m]</span><br></pre></td></tr></tbody></table></figure>
<h2 id="2-éšæœºæ¢¯åº¦"><a href="#2-éšæœºæ¢¯åº¦" class="headerlink" title="2.éšæœºæ¢¯åº¦"></a>2.éšæœºæ¢¯åº¦</h2><h3 id="2-1ä»€ä¹ˆæ˜¯æ¢¯åº¦"><a href="#2-1ä»€ä¹ˆæ˜¯æ¢¯åº¦" class="headerlink" title="2.1ä»€ä¹ˆæ˜¯æ¢¯åº¦"></a>2.1ä»€ä¹ˆæ˜¯æ¢¯åº¦</h3><p><img src="/2022/06/29/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF4-%E6%A2%AF%E5%BA%A6%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/image-20200727115800238.png" alt="image-20200727115800238" style="zoom:33%;"></p>
<p><strong>Optimizer Performance</strong></p>
<p>â–ª initialization statusï¼ˆåˆå§‹å€¼ï¼‰</p>
<p>â–ª learning rateï¼ˆå­¦ä¹ ç‡ï¼‰</p>
<p>â–ª momentumï¼ˆåŠ¨é‡ï¼Œæƒ¯æ€§ï¼‰</p>
<h3 id="2-2æ¿€æ´»å‡½æ•°åŠå…¶æ¢¯åº¦"><a href="#2-2æ¿€æ´»å‡½æ•°åŠå…¶æ¢¯åº¦" class="headerlink" title="2.2æ¿€æ´»å‡½æ•°åŠå…¶æ¢¯åº¦"></a>2.2æ¿€æ´»å‡½æ•°åŠå…¶æ¢¯åº¦</h3><p>æ¿€æ´»å‡½æ•°ï¼š</p>
<p><img src="/2022/06/29/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF4-%E6%A2%AF%E5%BA%A6%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/image-20200727171458040.png" alt="image-20200727171458040" style="zoom:40%;"></p>
<p>æœ€ç®€å•çš„æ¿€æ´»å‡½æ•°ï¼š</p>
<p><img src="/2022/06/29/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF4-%E6%A2%AF%E5%BA%A6%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/image-20200727171550864.png" alt="image-20200727171550864"></p>
<p><strong>Sigmoid / Logistic</strong>å‡½æ•°â€”â€”å…‰æ»‘å¯å¯¼</p>
<p><img src="/2022/06/29/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF4-%E6%A2%AF%E5%BA%A6%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/image-20200727171607779.png" alt="image-20200727171607779"></p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{d}{d x} \sigma(x) &=\frac{d}{d x}\left(\frac{1}{1+e^{-x}}\right) \\
&=\frac{e^{-x}}{\left(1+e^{-x}\right)^{2}} \\
&=\frac{\left(1+e^{-x}\right)-1}{\left(1+e^{-x}\right)^{2}} \\
&=\frac{1+e^{-x}}{\left(1+e^{-x}\right)^{2}}-\left(\frac{1}{1+e^{-x}}\right)^{2} \\
&=\sigma(x)-\sigma(x)^{2} \\
\sigma^{\prime} &=\sigma(1-\sigma)
\end{aligned}</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a=torch.linspace(-<span class="number">100</span>,<span class="number">100</span>,<span class="number">10</span>)</span><br><span class="line">torch.sigmoid(a)</span><br></pre></td></tr></tbody></table></figure>
<p><strong>Tanh</strong>â€”â€”RNNä¸­ç”¨çš„è¾ƒå¤š</p>
<p><img src="/2022/06/29/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF4-%E6%A2%AF%E5%BA%A6%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/image-20200727171926170.png" alt="image-20200727171926170"></p>
<script type="math/tex; mode=display">
\begin{array}{l}
\frac{d}{d x} \tanh (x)=\frac{\left(e^{x}+e^{-x}\right)\left(e^{x}+e^{-x}\right)-\left(e^{x}-e^{-x}\right)\left(e^{x}-e^{-x}\right)}{\left(e^{x}+e^{-x}\right)^{2}} \\
=1-\frac{\left(e^{x}-e^{-x}\right)^{2}}{\left(e^{x}+e^{-x}\right)^{2}}=1-\tanh ^{2}(x)
\end{array}</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">a=torch.linspace(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">10</span>)</span><br><span class="line">torch.tanh(a)</span><br></pre></td></tr></tbody></table></figure>
<p><strong>Rectified Linear Unit</strong>â€”â€”RELUâ€”â€”éçº¿æ€§æ¿€æ´»å‡½æ•°</p>
<p><img src="/2022/06/29/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF4-%E6%A2%AF%E5%BA%A6%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/image-20200727172058939.png" alt="image-20200727172058939"></p>
<script type="math/tex; mode=display">
f^{\prime}(x)=\left\{\begin{array}{ll}
0 & \text { for } x<0 \\
1 & \text { for } x \geq 0
\end{array}\right.</script><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line">a=torch.linspace(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">10</span>)</span><br><span class="line">torch.relu(a)</span><br><span class="line">F.relu(a)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="2-3LOSSåŠå…¶æ¢¯åº¦"><a href="#2-3LOSSåŠå…¶æ¢¯åº¦" class="headerlink" title="2.3LOSSåŠå…¶æ¢¯åº¦"></a>2.3LOSSåŠå…¶æ¢¯åº¦</h3><p><strong>Mean Squared Error(MSE)</strong></p>
<script type="math/tex; mode=display">
\begin{array}{l}
\operatorname{loss} =\sum[y-(x w+b)]^{2} \\
L 2-\operatorname{norm}=|| y-(x w+b)||_{2} \\
\operatorname{loss} =\operatorname{norm}(y-(x w+b))^{2}
\end{array}</script><p><strong>Derivative</strong></p>
<script type="math/tex; mode=display">
\operatorname{loss} =\sum\left[y-f_{\theta}(x)\right]^{2} \\
\frac{ { \nabla loss }}{\nabla \theta}=2 \sum\left[y-f_{\theta}(x)\right] \times \frac{\nabla f_{\theta}(x)}{\nabla \theta}</script><ul>
<li><p><code>torch.autograd.grad(loss, [w1, w2,â€¦])</code>â€”â€”-&gt;<code>[w1 grad, w2 gradâ€¦]</code></p>
</li>
<li><p><code>loss.backward()</code> â€”-&gt;   <code>w1.grad   w2.grad</code></p>
</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x=torch.ones(<span class="number">1</span>)</span><br><span class="line">w=torch.full([<span class="number">1</span>],<span class="number">2</span>)</span><br><span class="line">w.requires_grad_()<span class="comment">#æ›´æ–°wçš„ä¿¡æ¯ä¸ºå¯æ±‚å¯¼çš„</span></span><br><span class="line">mse=F.mse_loss(torch.ones(<span class="number">1</span>),x*w)<span class="comment">#é‡æ–°ç»˜åˆ¶åŠ¨æ€å›¾</span></span><br><span class="line">torch.autograd.grad(mse,[w])</span><br></pre></td></tr></tbody></table></figure>
<p><strong>softmax</strong></p>
<p><img src="/2022/06/29/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF4-%E6%A2%AF%E5%BA%A6%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/image-20200727174154540.png" alt="image-20200727174154540" style="zoom:80%;"></p>
<script type="math/tex; mode=display">
p_{i}=\frac{e^{a_{i}}}{\sum_{k=1}^{N} e^{a_{k}}}</script><script type="math/tex; mode=display">
when \ i=j
\begin{aligned}
\frac{\partial \frac{e^{a_{i}}}{\sum_{k=1}^{N} e^{a_{k}}}}{\partial a_{j}} &=\frac{e^{a_{i}} \sum_{k=1}^{N} e^{a_{k}}-e^{a_{j}} e^{a_{i}}}{\left(\sum_{k=1}^{N} e^{a_{k}}\right)^{2}} \\
&=\frac{e^{a_{i}}\left(\sum_{k=1}^{N} e^{a_{k}}-e^{a_{j}}\right)}{\left(\sum_{k=1}^{N} e^{a_{k}}\right)^{2}} \\
&=\frac{e^{a_{j}}}{\sum_{k=1}^{N} e^{a_{k}}} \times \frac{\left(\sum_{k=1}^{N} e^{a_{k}}-e^{a_{j}}\right)}{\sum_{k=1}^{N} e^{a_{k}}} \\
&=p_{i}\left(1-p_{j}\right)
\end{aligned}</script><script type="math/tex; mode=display">
when\ \ \   i \neq j   \begin{aligned} \frac{\partial \frac{e^{a_{i}}}{\sum_{k=1}^{N} e^{a_{k}}}}{\partial a_{j}} &=\frac{0-e^{a_{j}} e^{a_{i}}}{\left(\sum_{k=1}^{N} e^{a_{k}}\right)^{2}} \\ &=\frac{-e^{a_{j}}}{\sum_{k=1}^{N} e^{a_{k}}} \times \frac{e^{a_{i}}}{\sum_{k=1}^{N} e^{a_{k}}} \\ &=-p_{j} \cdot p_{i} \end{aligned}</script><p><img src="/2022/06/29/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF4-%E6%A2%AF%E5%BA%A6%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/image-20200727174942214.png" alt="image-20200727174942214" style="zoom:60%;"></p>
<h3 id="2-4åˆ©ç”¨pytorchå®ç°çº¿æ€§å›å½’"><a href="#2-4åˆ©ç”¨pytorchå®ç°çº¿æ€§å›å½’" class="headerlink" title="2.4åˆ©ç”¨pytorchå®ç°çº¿æ€§å›å½’"></a>2.4åˆ©ç”¨pytorchå®ç°çº¿æ€§å›å½’</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">torch.manual_seed(<span class="number">10</span>)</span><br><span class="line">lr = <span class="number">0.05</span>  <span class="comment"># å­¦ä¹ ç‡    20191015ä¿®æ”¹</span></span><br><span class="line"><span class="comment"># åˆ›å»ºè®­ç»ƒæ•°æ®</span></span><br><span class="line">x = torch.rand(<span class="number">20</span>, <span class="number">1</span>) * <span class="number">10</span>  <span class="comment"># x data (tensor), shape=(20, 1)</span></span><br><span class="line">y = <span class="number">2</span>*x + (<span class="number">5</span> + torch.randn(<span class="number">20</span>, <span class="number">1</span>))  <span class="comment"># y data (tensor), shape=(20, 1)</span></span><br><span class="line"><span class="comment"># æ„å»ºçº¿æ€§å›å½’å‚æ•°</span></span><br><span class="line">w = torch.randn((<span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.zeros((<span class="number">1</span>), requires_grad=<span class="literal">True</span>)<span class="comment">#éšæœºåˆå§‹åŒ–å¯æ±‚å¯¼</span></span><br><span class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    <span class="comment"># å‰å‘ä¼ æ’­</span></span><br><span class="line">    wx = torch.mul(w, x)</span><br><span class="line">    y_pred = torch.add(wx, b)</span><br><span class="line">    <span class="comment"># è®¡ç®— MSE loss</span></span><br><span class="line">    loss = (<span class="number">0.5</span> * (y - y_pred) ** <span class="number">2</span>).mean()</span><br><span class="line">    <span class="comment"># åå‘ä¼ æ’­</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="comment"># æ›´æ–°å‚æ•°</span></span><br><span class="line">    b.data.sub_(lr * b.grad)</span><br><span class="line">    w.data.sub_(lr * w.grad)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="3-è‡ªåŠ¨æ±‚å¯¼"><a href="#3-è‡ªåŠ¨æ±‚å¯¼" class="headerlink" title="3.è‡ªåŠ¨æ±‚å¯¼"></a>3.è‡ªåŠ¨æ±‚å¯¼</h2><h3 id="3-1torch-autograd"><a href="#3-1torch-autograd" class="headerlink" title="3.1torch.autograd"></a>3.1torch.autograd</h3><ul>
<li><code>torch.autograd.backward</code></li>
<li>åŠŸèƒ½ï¼šè‡ªåŠ¨æ±‚å–æ¢¯åº¦</li>
<li>å‡½æ•°è¯´æ˜å¦‚ä¸‹ï¼š</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ç¬¬ä¸€ä¸ªå¸¸ç”¨çš„å‡½æ•°</span></span><br><span class="line">torch.autograd.backward(tensors,</span><br><span class="line">                        grad_tensors=<span class="literal">None</span>,<span class="comment">#å¤šæ¢¯åº¦æƒé‡</span></span><br><span class="line">                        retain_graph=<span class="literal">None</span>,<span class="comment">#ä¿å­˜è®¡ç®—å›¾</span></span><br><span class="line">                        create_graph=<span class="literal">False</span>)<span class="comment">#åˆ›å»ºå¯¼æ•°è®¡ç®—å›¾ï¼Œç”¨äºé«˜é˜¶æ±‚å¯¼</span></span><br></pre></td></tr></tbody></table></figure>
<p>ä½¿ç”¨åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦ï¼š</p>
<ul>
<li><code>retain_graph=True</code>ç”¨äºä¿å­˜åŠ¨æ€å›¾</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">w = torch.tensor([<span class="number">1.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">x = torch.tensor([<span class="number">2.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">a = torch.add(w, x)</span><br><span class="line">b = torch.add(w, <span class="number">1</span>)</span><br><span class="line">y = torch.mul(a, b)</span><br><span class="line">y.backward(retain_graph=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(w.grad)</span><br><span class="line">y.backward()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/06/29/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF4-%E6%A2%AF%E5%BA%A6%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/image-20220629144735977.png" alt="image-20220629144735977"></p>
<ul>
<li><code>gradient=grad_tensors</code>ç”¨äºå¤šä¸ªæ¢¯åº¦ä¹‹é—´çš„æƒé‡è®¡ç®—</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">w = torch.tensor([<span class="number">1.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">x = torch.tensor([<span class="number">2.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">a = torch.add(w, x)     <span class="comment"># retain_grad()</span></span><br><span class="line">b = torch.add(w, <span class="number">1</span>)</span><br><span class="line">y0 = torch.mul(a, b)    <span class="comment"># y0 = (x+w) * (w+1)</span></span><br><span class="line">y1 = torch.add(a, b)    <span class="comment"># y1 = (x+w) + (w+1)    dy1/dw = 2</span></span><br><span class="line">loss = torch.cat([y0, y1], dim=<span class="number">0</span>)       <span class="comment"># [y0, y1]</span></span><br><span class="line">grad_tensors = torch.tensor([<span class="number">1.</span>, <span class="number">2.</span>])</span><br><span class="line">loss.backward(gradient=grad_tensors)    </span><br><span class="line"><span class="comment"># gradient ä¼ å…¥ torch.autograd.backward()ä¸­çš„grad_tensors</span></span><br><span class="line"><span class="built_in">print</span>(w.grad)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/06/29/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF4-%E6%A2%AF%E5%BA%A6%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/image-20220629144753443.png" alt="image-20220629144753443"></p>
<ul>
<li><code>torch.autograd.grad</code></li>
<li>åŠŸèƒ½ï¼šæ±‚å–æ¢¯åº¦</li>
<li>å‡½æ•°è¯´æ˜å¦‚ä¸‹ï¼š</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">torch.autograd.grad(outputs,<span class="comment">#ç”¨äºæ±‚å¯¼çš„å¼ é‡</span></span><br><span class="line">                    inputs,<span class="comment">#éœ€è¦æ¢¯åº¦çš„å¼ é‡</span></span><br><span class="line">                    grad_tensors=<span class="literal">None</span>,<span class="comment">#å¤šæ¢¯åº¦æƒé‡</span></span><br><span class="line">                    retain_graph=<span class="literal">None</span>,<span class="comment">#ä¿å­˜è®¡ç®—å›¾</span></span><br><span class="line">                    create_graph=<span class="literal">False</span>)<span class="comment">#åˆ›å»ºå¯¼æ•°è®¡ç®—å›¾ï¼Œç”¨äºé«˜é˜¶æ±‚å¯¼</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">3.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = torch.<span class="built_in">pow</span>(x, <span class="number">2</span>)     <span class="comment"># y = x**2</span></span><br><span class="line">grad_1 = torch.autograd.grad(y, x, create_graph=<span class="literal">True</span>)   </span><br><span class="line"><span class="comment"># grad_1 = dy/dx = 2x = 2 * 3 = 6</span></span><br><span class="line"><span class="built_in">print</span>(grad_1)</span><br><span class="line">grad_2 = torch.autograd.grad(grad_1[<span class="number">0</span>], x)              </span><br><span class="line"><span class="comment"># grad_2 = d(dy/dx)/dx = d(2x)/dx = 2</span></span><br><span class="line"><span class="built_in">print</span>(grad_2)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/06/29/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF4-%E6%A2%AF%E5%BA%A6%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/image-20220629144816196.png" alt="image-20220629144816196"></p>
<p><strong>autogradå°è´´å£«ï¼š</strong></p>
<ul>
<li><strong>æ¢¯åº¦ä¸è‡ªåŠ¨æ¸…é›¶</strong></li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">w = torch.tensor([<span class="number">1.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">x = torch.tensor([<span class="number">2.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    a = torch.add(w, x)</span><br><span class="line">    b = torch.add(w, <span class="number">1</span>)</span><br><span class="line">    y = torch.mul(a, b)</span><br><span class="line">    y.backward()</span><br><span class="line">    <span class="built_in">print</span>(w.grad)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/06/29/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF4-%E6%A2%AF%E5%BA%A6%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/image-20220629144836358.png" alt="image-20220629144836358"></p>
<ul>
<li><strong>ä¾èµ–äºå¶å­ç»“ç‚¹çš„ç»“ç‚¹ï¼Œrequires_gradé»˜è®¤ä¸ºTrue</strong></li>
<li><strong>å¶å­ç»“ç‚¹ä¸å¯æ‰§è¡Œin-place</strong></li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = torch.ones((<span class="number">1</span>, ))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(a), a)</span><br><span class="line">a = a + torch.ones((<span class="number">1</span>, ))<span class="comment">#in_placeæ“ä½œ</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(a), a)</span><br><span class="line">a += torch.ones((<span class="number">1</span>, ))<span class="comment">#placeæ“ä½œ</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(a), a)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/2022/06/29/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF4-%E6%A2%AF%E5%BA%A6%E4%B8%8E%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/image-20220629144852097.png" alt="image-20220629144852097"></p>
<h3 id="3-2é€»è¾‘å›å½’"><a href="#3-2é€»è¾‘å›å½’" class="headerlink" title="3.2é€»è¾‘å›å½’"></a>3.2é€»è¾‘å›å½’</h3><p>åˆ©ç”¨pytorchç”Ÿæˆè®­ç»ƒçš„æ•°æ®</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot sas plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#step1:æ•°æ®</span></span><br><span class="line">sample_nums=<span class="number">100</span></span><br><span class="line">mean_value=<span class="number">1.7</span></span><br><span class="line">bias=<span class="number">100</span></span><br><span class="line">n_data=torch.ones(sample_nums,<span class="number">2</span>)</span><br><span class="line">x0=torch.normal(mean_value*n_data,<span class="number">1</span>)+bias     <span class="comment">#ç±»åˆ«0 æ•°æ®shape=(100,2)</span></span><br><span class="line">y0=torch.zeros(sample_nums)                   <span class="comment">#ç±»åˆ«0 æ ‡ç­¾shape=(100,1)</span></span><br><span class="line">x1=torch.normal(-mean_value*n_data,<span class="number">1</span>)+bias    <span class="comment">#ç±»åˆ«1 æ•°æ®shape=(100,2)</span></span><br><span class="line">y0=torch.zeros(sample_nums)                   <span class="comment">#ç±»åˆ«1 æ ‡ç­¾shape=(100,1) </span></span><br><span class="line">train_x=torch.cat((x0,x1),<span class="number">0</span>)</span><br><span class="line">train_y=torch.cat((y0,y1),<span class="number">0</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>é€‰æ‹©æ¨¡å‹ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#step2:æ¨¡å‹</span></span><br><span class="line"><span class="comment">#å®šä¹‰é€»è¾‘å›å½’ä¸­çš„å‰å‘ä¼ æ’­ç®—æ³•</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LR</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):<span class="comment">#ç»§æ‰¿è‡ªnn.Moduleç±»</span></span><br><span class="line">        <span class="built_in">super</span>(LR,self).__init__()</span><br><span class="line">        self.features=nn.Linear(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">        self.sigmoid=nn.Sigmoid()</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x=self.features(x)</span><br><span class="line">        x=self.sigmoid(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"><span class="comment">#å®ä¾‹åŒ–é€»è¾‘å›å½’æ¨¡å‹</span></span><br><span class="line">lr_net=LR()</span><br></pre></td></tr></tbody></table></figure>
<p>å®šä¹‰æŸå¤±å‡½æ•°ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#step3:æŸå¤±å‡½æ•°</span></span><br><span class="line">loss_fn=nn.BCELoss()<span class="comment">#äº¤å‰ç†µæŸå¤±å‡½æ•°</span></span><br></pre></td></tr></tbody></table></figure>
<p>å®šä¹‰ä¼˜åŒ–å™¨ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#step4:ä¼˜åŒ–å™¨</span></span><br><span class="line">lr=<span class="number">0.01</span></span><br><span class="line">optimizer=torch.optim.SGD(lr_net.parameters(),lr=lr,momentum=<span class="number">0.9</span>)</span><br><span class="line"><span class="comment">#ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™çš„ä¼˜åŒ–å™¨</span></span><br></pre></td></tr></tbody></table></figure>
<p>è¿­ä»£è®­ç»ƒæ¨¡å‹</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#step5:è¿­ä»£è®­ç»ƒ</span></span><br><span class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    y_pred=lr_net(train_x)<span class="comment">#å‰å‘ä¼ æ’­</span></span><br><span class="line">    loss=loss_fn(y_pred.squeeze(),train_y)<span class="comment">#è®¡ç®—loss</span></span><br><span class="line">    loss.backward()<span class="comment">#åå‘ä¼ æ’­</span></span><br><span class="line">    optimizer.step()<span class="comment">#æ›´æ–°å‚æ•°</span></span><br><span class="line">    optimizer.zero_grad()<span class="comment">#æ¸…ç©ºæ¢¯åº¦</span></span><br><span class="line">    <span class="keyword">if</span> iteration % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        mask = y_pred.ge(<span class="number">0.5</span>).<span class="built_in">float</span>().squeeze()  <span class="comment"># ä»¥0.5ä¸ºé˜ˆå€¼è¿›è¡Œåˆ†ç±»</span></span><br><span class="line">        correct = (mask == train_y).<span class="built_in">sum</span>()  <span class="comment"># è®¡ç®—æ­£ç¡®é¢„æµ‹çš„æ ·æœ¬ä¸ªæ•°</span></span><br><span class="line">        acc = correct.item() / train_y.size(<span class="number">0</span>)  <span class="comment"># è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡</span></span><br><span class="line">        plt.scatter(x0.data.numpy()[:, <span class="number">0</span>], x0.data.numpy()[:, <span class="number">1</span>], </span><br><span class="line">                    c=<span class="string">'r'</span>, label=<span class="string">'class 0'</span>)</span><br><span class="line">        plt.scatter(x1.data.numpy()[:, <span class="number">0</span>], x1.data.numpy()[:, <span class="number">1</span>], </span><br><span class="line">                    c=<span class="string">'b'</span>, label=<span class="string">'class 1'</span>)</span><br><span class="line">        w0, w1 = lr_net.features.weight[<span class="number">0</span>]</span><br><span class="line">        w0, w1 = <span class="built_in">float</span>(w0.item()), <span class="built_in">float</span>(w1.item())</span><br><span class="line">        plot_b = <span class="built_in">float</span>(lr_net.features.bias[<span class="number">0</span>].item())</span><br><span class="line">        plot_x = np.arange(-<span class="number">6</span>, <span class="number">6</span>, <span class="number">0.1</span>)</span><br><span class="line">        plot_y = (-w0 * plot_x - plot_b) / w1</span><br><span class="line">        plt.xlim(-<span class="number">5</span>, <span class="number">7</span>)</span><br><span class="line">        plt.ylim(-<span class="number">7</span>, <span class="number">7</span>)</span><br><span class="line">        plt.plot(plot_x, plot_y)</span><br><span class="line">        plt.text(-<span class="number">5</span>, <span class="number">5</span>, <span class="string">'Loss=%.4f'</span> % loss.data.numpy(), </span><br><span class="line">                 fontdict={<span class="string">'size'</span>: <span class="number">20</span>, <span class="string">'color'</span>: <span class="string">'red'</span>})</span><br><span class="line">        plt.title(<span class="string">"Iteration: {}\nw0:{:.2f} w1:{:.2f} b: {:.2f} accuracy:{:.2%}"</span></span><br><span class="line">                  .<span class="built_in">format</span>(iteration, w0, w1, plot_b, acc))</span><br><span class="line">        plt.legend()</span><br><span class="line">        plt.show()</span><br><span class="line">        plt.pause(<span class="number">0.5</span>)</span><br><span class="line">        <span class="keyword">if</span> acc &gt; <span class="number">0.99</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></tbody></table></figure>

        </div>

        
            <section class="post-copyright">
                
                
                
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E7%BC%96%E7%A8%8B/">ğŸ·ï¸ç¼–ç¨‹</a>
                    
                        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">ğŸ·ï¸æ·±åº¦å­¦ä¹ </a>
                    
                        <a href="/tags/Pytorch/">ğŸ·ï¸Pytorch</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>Â· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2022/06/29/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF5-pytorch%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E6%9C%BA%E5%88%B6/">pytorchæ—¥ç§¯æœˆç´¯-pytorchæ•°æ®è¯»å–æœºåˆ¶</a>
            
            
            <a class="next" rel="next" href="/2022/06/29/pytorch%E6%97%A5%E7%A7%AF%E6%9C%88%E7%B4%AF3-%E8%AE%A1%E7%AE%97%E5%9B%BE%E4%B8%8E%E5%8A%A8%E6%80%81%E5%9B%BE%E6%9C%BA%E5%88%B6/">pytorchæ—¥ç§¯æœˆç´¯-è®¡ç®—å›¾ä¸åŠ¨æ€å›¾æœºåˆ¶</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>Â© å°¹ç¥ºç¿” | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>

</html>